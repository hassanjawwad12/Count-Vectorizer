# -*- coding: utf-8 -*-
"""Count-Vectorizer

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YgCDuwT2XIJYCTinhPkroar0e8En14MQ
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer

import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.tokenize import word_tokenize

nltk.download('punkt')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

# https://www.kaggle.com/shivamkushwaha/bbc-full-text-document-classification
!wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv

df=pd.read_csv('bbc_text_cls.csv')
df.head()

input=df['text']
label=df['labels']

label.hist(figsize=(10,5))

input_train,input_test,label_train,label_test=train_test_split(input,label,test_size=0.2,random_state=123)

vectorizer=CountVectorizer()

X_train=vectorizer.fit_transform(input_train)
X_test=vectorizer.transform(input_test)

X_train

(X_train!=0).sum()

#what percentage of values are non zero
(X_train!=0).sum() / np.product(X_train.shape)

model=MultinomialNB()
model.fit(X_train,label_train)
print ('train score:',model.score(X_train,label_train))
print ('test score:',model.score(X_test,label_test))

#with stopwords
vectorizer=CountVectorizer(stop_words='english')
X_train=vectorizer.fit_transform(input_train)
X_test=vectorizer.transform(input_test)
model=MultinomialNB()
model.fit(X_train,label_train)
print ('train score:',model.score(X_train,label_train))
print ('test score:',model.score(X_test,label_test))

from nltk.corpus import wordnet

def get_wordnet_pos(tag):
  if tag.startswith('J'):
    return wordnet.ADJ
  if tag.startswith('V'):
    return wordnet.VERB
  if tag.startswith('N'):
    return wordnet.NOUN
  if tag.startswith('R'):
    return wordnet.ADV
  else:
    return wordnet.NOUN

class LemmaTokenizer:
    def __init__(self):
        self.wnl = WordNetLemmatizer()

    def __call__(self, doc):
        tokens = word_tokenize(doc)
        words_and_tags = nltk.pos_tag(tokens)
        return [self.wnl.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in words_and_tags]

vectorizer=CountVectorizer(tokenizer=LemmaTokenizer())
X_train=vectorizer.fit_transform(input_train)
X_test=vectorizer.transform(input_test)
model=MultinomialNB()
model.fit(X_train,label_train)
print ('train score:',model.score(X_train,label_train))
print ('test score:',model.score(X_test,label_test))

class StemTokenizer:
    def __init__(self):
        self.stemmer = PorterStemmer()

    def __call__(self, doc):
        tokens = word_tokenize(doc)
        return [self.stemmer.stem(token) for token in tokens]

vectorizer=CountVectorizer(tokenizer=StemTokenizer())
X_train=vectorizer.fit_transform(input_train)
X_test=vectorizer.transform(input_test)
model=MultinomialNB()
model.fit(X_train,label_train)
print ('train score:',model.score(X_train,label_train))
print ('test score:',model.score(X_test,label_test))

def simple_tokenizer(s):
  return s.split()

vectorizer=CountVectorizer(tokenizer=simple_tokenizer)
X_train=vectorizer.fit_transform(input_train)
X_test=vectorizer.transform(input_test)
model=MultinomialNB()
model.fit(X_train,label_train)
print ('train score:',model.score(X_train,label_train))
print ('test score:',model.score(X_test,label_test))

